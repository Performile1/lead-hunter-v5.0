# üîç Unified Search Strategy - Scraping + API:er

**Syfte:** En s√∂kning som kombinerar scraping och API:er f√∂r att h√§mta all data  
**Strategi:** Anv√§nd scraping tills alla API:er √§r p√• plats  
**Version:** 5.0  
**Datum:** 2025-12-17

---

## üéØ **VISION:**

### **En s√∂kning - all data:**
```
S√∂k f√∂retag ‚Üí Unified Search ‚Üí Komplett leadkort
```

**Datak√§llor (i prioritetsordning):**
1. Allabolag (oms√§ttning, ekonomi)
2. Bolagsverket (grundl√§ggande f√∂retagsinfo)
3. Kronofogden (betalningsanm√§rkningar)
4. LinkedIn (kontaktpersoner: VD, CFO, Logistikchef)
5. F√∂retagets webbplats (e-handel, teknologier, leverant√∂rer)
6. Nyheter (expansion, tillv√§xt, investeringar)

---

## üìä **NUL√ÑGE: Hybrid Scraping + API**

### **Vad som fungerar idag:**

#### **‚úÖ Firecrawl API (Implementerad)**
**Anv√§nds f√∂r:**
- Allabolag-scraping (oms√§ttning, kreditbetyg)
- F√∂retagswebbplatser (struktur, inneh√•ll)
- Nyhetsartiklar

**Status:** ‚úÖ Fungerar, 4 endpoints implementerade

#### **‚úÖ Gemini AI (Implementerad)**
**Anv√§nds f√∂r:**
- AI-analys av f√∂retagsdata
- Opportunity score
- Sales pitch
- Triggers
- Kontaktpersoner (VD, CFO, Logistikchef)

**Status:** ‚úÖ Fungerar, fallback till Groq

#### **‚úÖ Groq AI (Implementerad)**
**Anv√§nds f√∂r:**
- Fallback n√§r Gemini n√•r quota
- Snabbare analys (mindre noggrann)

**Status:** ‚úÖ Fungerar som fallback

#### **‚ö†Ô∏è Puppeteer (Implementerad men ej integrerad)**
**Kan anv√§ndas f√∂r:**
- Dynamiska webbplatser
- JavaScript-tunga sidor
- E-handelsplattformar
- Checkout-analys

**Status:** ‚ö†Ô∏è Finns i `hybridScraperService.ts` men anv√§nds INTE

#### **‚ùå Crawl4AI (Stub)**
**Skulle kunna anv√§ndas f√∂r:**
- AI-driven scraping
- Intelligent extraktion

**Status:** ‚ùå Kr√§ver Python backend (inte implementerad)

---

## üîÑ **UNIFIED SEARCH FLOW:**

### **Steg 1: Grundl√§ggande f√∂retagsinfo**
```
Input: F√∂retagsnamn eller org.nr
‚Üì
Bolagsverket (scraping eller API)
‚Üì
Output: Namn, org.nr, adress, bransch
```

**Metod:** Scraping (tills Bolagsverket API finns)

---

### **Steg 2: Ekonomisk data**
```
Input: Org.nr
‚Üì
Allabolag (Firecrawl scraping)
‚Üì
Output: Oms√§ttning, kreditbetyg, antal anst√§llda
```

**Metod:** ‚úÖ Firecrawl (implementerad i `allabolagScraper.ts`)

---

### **Steg 3: Betalningsanm√§rkningar**
```
Input: Org.nr
‚Üì
Kronofogden (scraping eller API)
‚Üì
Output: Antal anm√§rkningar, belopp
```

**Metod:** Scraping (tills Kronofogden API finns)

---

### **Steg 4: Kontaktpersoner**
```
Input: F√∂retagsnamn
‚Üì
LinkedIn (Gemini AI-s√∂kning)
‚Üì
Output: VD, CFO, Logistikchef (namn, titel, LinkedIn-URL)
```

**Metod:** ‚úÖ Gemini AI (implementerad i `geminiService.ts`)

---

### **Steg 5: E-handel & Teknologier**
```
Input: F√∂retagswebbplats
‚Üì
Firecrawl scraping + Puppeteer
‚Üì
Output: E-handelsplattform, checkout, leverant√∂rer, teknologier
```

**Metod:** 
- ‚úÖ Firecrawl f√∂r grundl√§ggande scraping
- ‚ö†Ô∏è Puppeteer f√∂r dynamiska sidor (ej integrerad)

---

### **Steg 6: Nyheter**
```
Input: F√∂retagsnamn
‚Üì
NewsAPI eller Firecrawl
‚Üì
Output: Senaste nyheter, expansion, investeringar
```

**Metod:** 
- ‚ö†Ô∏è NewsAPI (API-nyckel saknas)
- ‚úÖ Firecrawl som fallback

---

## üèóÔ∏è **IMPLEMENTATION PLAN:**

### **Fas 1: F√∂rb√§ttra befintlig scraping (2-3h)**

#### **1.1 Integrera Puppeteer i geminiService (2h)**

**Fil:** `services/geminiService.ts`

**L√§gg till:**
```typescript
import { scrapeWithPuppeteer } from './hybridScraperService';

// I generateLeads-funktionen:
const scrapedData = await scrapeWithPuppeteer(companyWebsite);
const ecommerceData = {
  platform: scrapedData.ecommercePlatform,
  checkout: scrapedData.checkoutProvider,
  carriers: scrapedData.shippingProviders,
  technologies: scrapedData.technologies
};
```

**Resultat:** B√§ttre e-handelsdata fr√•n dynamiska sidor

---

#### **1.2 L√§gg till Bolagsverket-scraping (1h)**

**Skapa:** `services/bolagsverketScraper.ts`

```typescript
export async function scrapeBolagsverket(orgNumber: string) {
  const url = `https://www.bolagsverket.se/ff/foretagsformer/aktiebolag/${orgNumber}`;
  
  const result = await scrapeWithFirecrawl(url, {
    formats: ['markdown'],
    onlyMainContent: true
  });
  
  return {
    name: extractCompanyName(result.markdown),
    orgNumber: orgNumber,
    address: extractAddress(result.markdown),
    industry: extractIndustry(result.markdown),
    registrationDate: extractRegistrationDate(result.markdown)
  };
}
```

**Resultat:** Grundl√§ggande f√∂retagsinfo fr√•n officiell k√§lla

---

#### **1.3 L√§gg till Kronofogden-scraping (1h)**

**Skapa:** `services/kronofogdenScraper.ts`

```typescript
export async function scrapeKronofogden(orgNumber: string) {
  const url = `https://kronofogden.se/Sok-foretagsuppgifter.html?orgNr=${orgNumber}`;
  
  const result = await scrapeWithFirecrawl(url, {
    formats: ['markdown'],
    onlyMainContent: true
  });
  
  return {
    hasRemarks: checkForRemarks(result.markdown),
    remarkCount: extractRemarkCount(result.markdown),
    totalAmount: extractTotalAmount(result.markdown),
    lastChecked: new Date().toISOString()
  };
}
```

**Resultat:** Betalningsanm√§rkningar fr√•n officiell k√§lla

---

### **Fas 2: Unified Search Service (3-4h)**

#### **2.1 Skapa UnifiedSearchService (2h)**

**Skapa:** `services/unifiedSearchService.ts`

```typescript
export async function unifiedSearch(query: string) {
  const results = {
    basicInfo: null,
    financialData: null,
    creditCheck: null,
    contacts: null,
    ecommerce: null,
    news: null
  };
  
  // Steg 1: Grundl√§ggande info (Bolagsverket)
  try {
    results.basicInfo = await scrapeBolagsverket(query);
  } catch (error) {
    console.error('Bolagsverket scraping failed:', error);
  }
  
  // Steg 2: Ekonomisk data (Allabolag)
  try {
    results.financialData = await scrapeAllabolag(query);
  } catch (error) {
    console.error('Allabolag scraping failed:', error);
  }
  
  // Steg 3: Kreditcheck (Kronofogden)
  try {
    results.creditCheck = await scrapeKronofogden(query);
  } catch (error) {
    console.error('Kronofogden scraping failed:', error);
  }
  
  // Steg 4: Kontaktpersoner (Gemini AI)
  try {
    results.contacts = await findContactsWithAI(results.basicInfo.name);
  } catch (error) {
    console.error('Contact search failed:', error);
  }
  
  // Steg 5: E-handel (Puppeteer + Firecrawl)
  try {
    const website = results.basicInfo.website;
    if (website) {
      results.ecommerce = await scrapeWithPuppeteer(website);
    }
  } catch (error) {
    console.error('E-commerce scraping failed:', error);
  }
  
  // Steg 6: Nyheter (NewsAPI eller Firecrawl)
  try {
    results.news = await searchNews(results.basicInfo.name);
  } catch (error) {
    console.error('News search failed:', error);
  }
  
  return results;
}
```

**Resultat:** En funktion som h√§mtar ALL data fr√•n alla k√§llor

---

#### **2.2 Integrera i geminiService (1h)**

**Fil:** `services/geminiService.ts`

**Ers√§tt nuvarande datah√§mtning med:**
```typescript
import { unifiedSearch } from './unifiedSearchService';

export async function generateLeads(formData: SearchFormData): Promise<LeadData[]> {
  const companies = formData.companies.split('\n').filter(c => c.trim());
  const leads: LeadData[] = [];
  
  for (const company of companies) {
    try {
      // Unified search h√§mtar ALL data
      const data = await unifiedSearch(company);
      
      // Bygg leadkort fr√•n unified data
      const lead = buildLeadCard(data);
      leads.push(lead);
      
    } catch (error) {
      console.error(`Failed to process ${company}:`, error);
    }
  }
  
  return leads;
}
```

**Resultat:** Alla leads f√•r komplett data fr√•n alla k√§llor

---

#### **2.3 Felhantering & Fallbacks (1h)**

**Strategi:**
```typescript
// Om Bolagsverket misslyckas ‚Üí Anv√§nd Allabolag
// Om Allabolag misslyckas ‚Üí Anv√§nd Google Search (Firecrawl)
// Om Kronofogden misslyckas ‚Üí Markera som "Ej kontrollerad"
// Om Gemini misslyckas ‚Üí Anv√§nd Groq
// Om Puppeteer misslyckas ‚Üí Anv√§nd Firecrawl
// Om NewsAPI misslyckas ‚Üí Anv√§nd Firecrawl news search
```

**Implementation:**
```typescript
async function getFinancialData(orgNumber: string) {
  try {
    return await scrapeAllabolag(orgNumber);
  } catch (error) {
    console.warn('Allabolag failed, trying Google Search...');
    try {
      return await searchWithFirecrawl(`${orgNumber} oms√§ttning`);
    } catch (fallbackError) {
      console.error('All financial data sources failed');
      return null;
    }
  }
}
```

**Resultat:** Systemet fungerar √§ven om enskilda k√§llor misslyckas

---

### **Fas 3: API-migration (framtida)**

#### **N√§r API:er blir tillg√§ngliga:**

**Prioritet 1: Bolagsverket API**
- Ers√§tt scraping med officiellt API
- Snabbare och mer p√•litligt
- Mindre risk f√∂r blockering

**Prioritet 2: Kronofogden API**
- Ers√§tt scraping med officiellt API
- Mer aktuell data
- Juridiskt s√§krare

**Prioritet 3: UC/Ratsit API**
- L√§gg till f√∂r kreditbetyg
- Komplettera Allabolag-data
- Betald tj√§nst

**Prioritet 4: BuiltWith/Wappalyzer API**
- Ers√§tt Puppeteer f√∂r teknologier
- Mer omfattande data
- Betald tj√§nst

---

## üìã **DATAK√ÑLLOR STATUS:**

### **üü¢ Fungerar (Scraping eller API):**

| K√§lla | Metod | Data | Status |
|-------|-------|------|--------|
| Allabolag | Firecrawl | Oms√§ttning, kreditbetyg | ‚úÖ Fungerar |
| F√∂retagswebbplats | Firecrawl | Struktur, inneh√•ll | ‚úÖ Fungerar |
| LinkedIn | Gemini AI | Kontaktpersoner | ‚úÖ Fungerar |
| AI-analys | Gemini/Groq | Opportunity score, pitch | ‚úÖ Fungerar |

### **üü° Delvis implementerad:**

| K√§lla | Metod | Data | Status |
|-------|-------|------|--------|
| E-handel | Puppeteer | Plattform, checkout | ‚ö†Ô∏è Finns men ej integrerad |
| Nyheter | NewsAPI | Senaste nyheter | ‚ö†Ô∏è API-nyckel saknas |

### **üî¥ Saknas (Beh√∂ver implementeras):**

| K√§lla | Metod | Data | Prioritet |
|-------|-------|------|-----------|
| Bolagsverket | Scraping | Grundl√§ggande info | üî¥ H√∂g |
| Kronofogden | Scraping | Betalningsanm√§rkningar | üî¥ H√∂g |
| UC/Ratsit | API | Kreditbetyg (betald) | üü° Medel |
| BuiltWith | API | Teknologier (betald) | üü¢ L√•g |
| Wappalyzer | API | Teknologier (betald) | üü¢ L√•g |

---

## üéØ **REKOMMENDERAD IMPLEMENTATION:**

### **Vecka 1: F√∂rb√§ttra scraping (6-7h)**

**Dag 1-2:**
- ‚úÖ Integrera Puppeteer i geminiService (2h)
- ‚úÖ Skapa bolagsverketScraper.ts (1h)
- ‚úÖ Skapa kronofogdenScraper.ts (1h)

**Dag 3:**
- ‚úÖ Skapa unifiedSearchService.ts (2h)
- ‚úÖ Integrera i geminiService.ts (1h)

**Dag 4:**
- ‚úÖ Testa unified search (1h)
- ‚úÖ Felhantering & fallbacks (1h)

**Resultat:** Komplett unified search med scraping

---

### **Vecka 2: Optimering (4-5h)**

**Dag 1:**
- ‚úÖ Parallellisera API-anrop (2h)
- ‚úÖ L√§gg till caching (1h)

**Dag 2:**
- ‚úÖ F√∂rb√§ttra felhantering (1h)
- ‚úÖ L√§gg till progress indicators (1h)

**Resultat:** Snabbare och mer robust

---

### **Framtid: API-migration (n√§r tillg√§ngligt)**

**N√§r Bolagsverket API finns:**
- Ers√§tt scraping med API (1h)

**N√§r Kronofogden API finns:**
- Ers√§tt scraping med API (1h)

**N√§r budget finns f√∂r betalda API:er:**
- L√§gg till UC/Ratsit (2h)
- L√§gg till BuiltWith/Wappalyzer (2h)

---

## üí° **F√ñRDELAR MED UNIFIED SEARCH:**

### **F√∂r anv√§ndare:**
- ‚úÖ En s√∂kning - all data
- ‚úÖ Snabbare (parallella anrop)
- ‚úÖ Mer komplett information
- ‚úÖ Automatisk fallback vid fel

### **F√∂r utveckling:**
- ‚úÖ Enklare att underh√•lla
- ‚úÖ Enklare att l√§gga till nya k√§llor
- ‚úÖ Enklare att migrera till API:er
- ‚úÖ B√§ttre felhantering

### **F√∂r systemet:**
- ‚úÖ Mindre kod-duplicering
- ‚úÖ Konsekvent dataformat
- ‚úÖ Enklare att testa
- ‚úÖ B√§ttre prestanda

---

## üöÄ **N√ÑSTA STEG:**

### **Prioritet 1: Implementera unified search (6-7h)**

1. **Integrera Puppeteer** (2h)
2. **Skapa Bolagsverket-scraper** (1h)
3. **Skapa Kronofogden-scraper** (1h)
4. **Skapa UnifiedSearchService** (2h)
5. **Integrera i geminiService** (1h)

### **Prioritet 2: Testa & optimera (2-3h)**

1. **Testa med riktiga f√∂retag** (1h)
2. **F√∂rb√§ttra felhantering** (1h)
3. **L√§gg till progress indicators** (1h)

### **Prioritet 3: Dokumentera (1h)**

1. **Uppdatera README.md** (30 min)
2. **Skapa API-dokumentation** (30 min)

---

## üìä **SAMMANFATTNING:**

### **Nul√§ge:**
- ‚úÖ Firecrawl fungerar (Allabolag, webbplatser)
- ‚úÖ Gemini AI fungerar (kontaktpersoner, analys)
- ‚ö†Ô∏è Puppeteer finns men ej integrerad
- ‚ùå Bolagsverket-scraping saknas
- ‚ùå Kronofogden-scraping saknas

### **M√•l:**
- ‚úÖ En unified search som h√§mtar ALL data
- ‚úÖ Scraping tills API:er finns
- ‚úÖ Automatisk fallback vid fel
- ‚úÖ Enkel att migrera till API:er

### **Tid:**
- **Fas 1:** 6-7h (Implementera unified search)
- **Fas 2:** 2-3h (Testa & optimera)
- **Fas 3:** Framtida (API-migration n√§r tillg√§ngligt)

**Total:** ~9-10h f√∂r komplett unified search med scraping

---

**Version:** 5.0  
**Status:** Strategi klar, redo f√∂r implementation  
**N√§sta:** Implementera Fas 1 (6-7h)

